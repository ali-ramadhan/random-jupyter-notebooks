{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import DelimitedFiles, Statistics, Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = Random.MersenneTwister(convert(Int64, rand(1:2e10)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "506×14 Array{Float64,2}:\n",
       " 0.00632  18.0   2.31  0.0  0.538  6.575  …  296.0  15.3  396.9    4.98  24.0\n",
       " 0.02731   0.0   7.07  0.0  0.469  6.421     242.0  17.8  396.9    9.14  21.6\n",
       " 0.02729   0.0   7.07  0.0  0.469  7.185     242.0  17.8  392.83   4.03  34.7\n",
       " 0.03237   0.0   2.18  0.0  0.458  6.998     222.0  18.7  394.63   2.94  33.4\n",
       " 0.06905   0.0   2.18  0.0  0.458  7.147     222.0  18.7  396.9    5.33  36.2\n",
       " 0.02985   0.0   2.18  0.0  0.458  6.43   …  222.0  18.7  394.12   5.21  28.7\n",
       " 0.08829  12.5   7.87  0.0  0.524  6.012     311.0  15.2  395.6   12.43  22.9\n",
       " 0.14455  12.5   7.87  0.0  0.524  6.172     311.0  15.2  396.9   19.15  27.1\n",
       " 0.21124  12.5   7.87  0.0  0.524  5.631     311.0  15.2  386.63  29.93  16.5\n",
       " 0.17004  12.5   7.87  0.0  0.524  6.004     311.0  15.2  386.71  17.1   18.9\n",
       " 0.22489  12.5   7.87  0.0  0.524  6.377  …  311.0  15.2  392.52  20.45  15.0\n",
       " 0.11747  12.5   7.87  0.0  0.524  6.009     311.0  15.2  396.9   13.27  18.9\n",
       " 0.09378  12.5   7.87  0.0  0.524  5.889     311.0  15.2  390.5   15.71  21.7\n",
       " ⋮                                 ⋮      ⋱          ⋮                       \n",
       " 0.27957   0.0   9.69  0.0  0.585  5.926     391.0  19.2  396.9   13.59  24.5\n",
       " 0.17899   0.0   9.69  0.0  0.585  5.67   …  391.0  19.2  393.29  17.6   23.1\n",
       " 0.2896    0.0   9.69  0.0  0.585  5.39      391.0  19.2  396.9   21.14  19.7\n",
       " 0.26838   0.0   9.69  0.0  0.585  5.794     391.0  19.2  396.9   14.1   18.3\n",
       " 0.23912   0.0   9.69  0.0  0.585  6.019     391.0  19.2  396.9   12.92  21.2\n",
       " 0.17783   0.0   9.69  0.0  0.585  5.569     391.0  19.2  395.77  15.1   17.5\n",
       " 0.22438   0.0   9.69  0.0  0.585  6.027  …  391.0  19.2  396.9   14.33  16.8\n",
       " 0.06263   0.0  11.93  0.0  0.573  6.593     273.0  21.0  391.99   9.67  22.4\n",
       " 0.04527   0.0  11.93  0.0  0.573  6.12      273.0  21.0  396.9    9.08  20.6\n",
       " 0.06076   0.0  11.93  0.0  0.573  6.976     273.0  21.0  396.9    5.64  23.9\n",
       " 0.10959   0.0  11.93  0.0  0.573  6.794     273.0  21.0  393.45   6.48  22.0\n",
       " 0.04741   0.0  11.93  0.0  0.573  6.03   …  273.0  21.0  396.9    7.88  11.9"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = DelimitedFiles.readdlm(\"housing.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×506 LinearAlgebra.Transpose{Float64,Array{Float64,1}}:\n",
       " 24.0  21.6  34.7  33.4  36.2  28.7  …  16.8  22.4  20.6  23.9  22.0  11.9"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_house_price = transpose(data[:,end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13×506 LinearAlgebra.Transpose{Float64,Array{Float64,2}}:\n",
       "   0.00632    0.02731    0.02729  …    0.06076    0.10959    0.04741\n",
       "  18.0        0.0        0.0           0.0        0.0        0.0    \n",
       "   2.31       7.07       7.07         11.93      11.93      11.93   \n",
       "   0.0        0.0        0.0           0.0        0.0        0.0    \n",
       "   0.538      0.469      0.469         0.573      0.573      0.573  \n",
       "   6.575      6.421      7.185    …    6.976      6.794      6.03   \n",
       "  65.2       78.9       61.1          91.0       89.3       80.8    \n",
       "   4.09       4.9671     4.9671        2.1675     2.3889     2.505  \n",
       "   1.0        2.0        2.0           1.0        1.0        1.0    \n",
       " 296.0      242.0      242.0         273.0      273.0      273.0    \n",
       "  15.3       17.8       17.8      …   21.0       21.0       21.0    \n",
       " 396.9      396.9      392.83        396.9      393.45     396.9    \n",
       "   4.98       9.14       4.03          5.64       6.48       7.88   "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_data = transpose(data[:,1:end-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols = size(housing_data)\n",
    "for r in 1:rows\n",
    "    row_mean = Statistics.mean(housing_data[r,:])\n",
    "    row_std = Statistics.std(housing_data[r,:])\n",
    "    housing_data[r,:] = (housing_data[r,:] .- row_mean) ./ row_std\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 400\n",
    "\n",
    "# Random.seed!(1)\n",
    "idx_perm = Random.randperm(rng, cols)\n",
    "idx_train = idx_perm[1:n_train]\n",
    "idx_test = idx_perm[n_train+1:end]\n",
    "\n",
    "housing_data_train = housing_data[:,idx_train];\n",
    "housing_data_test = housing_data[:,idx_test];\n",
    "median_house_price_train = median_house_price[idx_train];\n",
    "median_house_price_test = median_house_price[idx_test];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.142606 0.0952386 … -0.0170649 -0.0645505], [0.0])"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_and_bias = (transpose(0.1 .* randn(13)), [0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predict (generic function with 1 method)"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function predict(housing_data, weights_and_bias)\n",
    "    weights = weights_and_bias[1]\n",
    "    bias = weights_and_bias[2]\n",
    "    return (weights * housing_data) .+ bias\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×400 Array{Float64,2}:\n",
       " -0.247671  -0.00529168  -0.467821  …  0.187936  0.13619  0.0992343"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_house_price_pred = predict(housing_data_train, weights_and_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss (generic function with 2 methods)"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function loss(input, output, weights_and_bias)\n",
    "    N = size(input)[2]\n",
    "    return (1 / (2N)) * sum((predict(input, weights_and_bias) .- transpose(output)).^2)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss(housing_data_train, median_house_price_train, weights_and_bias) = 291.91905130729555\n",
      "loss(housing_data_test, median_house_price_test, weights_and_bias) = 316.2400623922435\n"
     ]
    }
   ],
   "source": [
    "@show loss(housing_data_train, median_house_price_train, weights_and_bias);\n",
    "@show loss(housing_data_test, median_house_price_test, weights_and_bias);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_better = 100\n"
     ]
    }
   ],
   "source": [
    "loss_value = √(loss(housing_data_train, median_house_price_train, weights_and_bias));\n",
    "abs_err = abs.(median_house_price_pred - transpose(median_house_price_train));\n",
    "n_better = sum(map(x -> x<loss_value, abs_err))\n",
    "\n",
    "@show n_better;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Usage:\n",
       "\n",
       "```\n",
       "x = Param([1,2,3])          # user declares parameters\n",
       "x => P([1,2,3])             # they are wrapped in a struct\n",
       "value(x) => [1,2,3]         # we can get the original value\n",
       "sum(abs2,x) => 14           # they act like regular values outside of differentiation\n",
       "y = @diff sum(abs2,x)       # if you want the gradients\n",
       "y => T(14)                  # you get another struct\n",
       "value(y) => 14              # which represents the same value\n",
       "grad(y,x) => [2,4,6]        # but also contains gradients for all Params\n",
       "```\n",
       "\n",
       "`Param(x)` returns a struct that acts like `x` but marks it as a parameter you want to compute gradients with respect to.\n",
       "\n",
       "`@diff expr` evaluates an expression and returns a struct that contains its value (which should be a scalar) and gradient information.\n",
       "\n",
       "`grad(y, x)` returns the gradient of `y` (output by @diff) with respect to any parameter `x::Param`, or  `nothing` if the gradient is 0.\n",
       "\n",
       "`value(x)` returns the value associated with `x` if `x` is a `Param` or the output of `@diff`, otherwise returns `x`.\n",
       "\n",
       "`params(x)` returns an array of Params found by a recursive search of object `x`.\n",
       "\n",
       "Alternative usage:\n",
       "\n",
       "```\n",
       "x = [1 2 3]\n",
       "f(x) = sum(abs2, x)\n",
       "f(x) => 14\n",
       "grad(f)(x) => [2 4 6]\n",
       "gradloss(f)(x) => ([2 4 6], 14)\n",
       "```\n",
       "\n",
       "Given a scalar valued function `f`, `grad(f,argnum=1)` returns another function `g` which takes the same inputs as `f` and returns the gradient of the output with respect to the argnum'th argument. `gradloss` is similar except the resulting function also returns f's output.\n"
      ],
      "text/plain": [
       "  Usage:\n",
       "\n",
       "\u001b[36m  x = Param([1,2,3])          # user declares parameters\u001b[39m\n",
       "\u001b[36m  x => P([1,2,3])             # they are wrapped in a struct\u001b[39m\n",
       "\u001b[36m  value(x) => [1,2,3]         # we can get the original value\u001b[39m\n",
       "\u001b[36m  sum(abs2,x) => 14           # they act like regular values outside of differentiation\u001b[39m\n",
       "\u001b[36m  y = @diff sum(abs2,x)       # if you want the gradients\u001b[39m\n",
       "\u001b[36m  y => T(14)                  # you get another struct\u001b[39m\n",
       "\u001b[36m  value(y) => 14              # which represents the same value\u001b[39m\n",
       "\u001b[36m  grad(y,x) => [2,4,6]        # but also contains gradients for all Params\u001b[39m\n",
       "\n",
       "  \u001b[36mParam(x)\u001b[39m returns a struct that acts like \u001b[36mx\u001b[39m but marks it as a parameter you\n",
       "  want to compute gradients with respect to.\n",
       "\n",
       "  \u001b[36m@diff expr\u001b[39m evaluates an expression and returns a struct that contains its\n",
       "  value (which should be a scalar) and gradient information.\n",
       "\n",
       "  \u001b[36mgrad(y, x)\u001b[39m returns the gradient of \u001b[36my\u001b[39m (output by @diff) with respect to any\n",
       "  parameter \u001b[36mx::Param\u001b[39m, or \u001b[36mnothing\u001b[39m if the gradient is 0.\n",
       "\n",
       "  \u001b[36mvalue(x)\u001b[39m returns the value associated with \u001b[36mx\u001b[39m if \u001b[36mx\u001b[39m is a \u001b[36mParam\u001b[39m or the output\n",
       "  of \u001b[36m@diff\u001b[39m, otherwise returns \u001b[36mx\u001b[39m.\n",
       "\n",
       "  \u001b[36mparams(x)\u001b[39m returns an array of Params found by a recursive search of object\n",
       "  \u001b[36mx\u001b[39m.\n",
       "\n",
       "  Alternative usage:\n",
       "\n",
       "\u001b[36m  x = [1 2 3]\u001b[39m\n",
       "\u001b[36m  f(x) = sum(abs2, x)\u001b[39m\n",
       "\u001b[36m  f(x) => 14\u001b[39m\n",
       "\u001b[36m  grad(f)(x) => [2 4 6]\u001b[39m\n",
       "\u001b[36m  gradloss(f)(x) => ([2 4 6], 14)\u001b[39m\n",
       "\n",
       "  Given a scalar valued function \u001b[36mf\u001b[39m, \u001b[36mgrad(f,argnum=1)\u001b[39m returns another function\n",
       "  \u001b[36mg\u001b[39m which takes the same inputs as \u001b[36mf\u001b[39m and returns the gradient of the output\n",
       "  with respect to the argnum'th argument. \u001b[36mgradloss\u001b[39m is similar except the\n",
       "  resulting function also returns f's output."
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Printf\n",
    "using Knet\n",
    "@doc Knet.AutoGrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=  0 \t train_loss=290.166 \t test_loss=317.698\n",
      "epoch=  1 \t train_loss=290.132 \t test_loss=317.786\n",
      "epoch=  2 \t train_loss=290.096 \t test_loss=317.884\n",
      "epoch=  3 \t train_loss=290.059 \t test_loss=317.993\n",
      "epoch=  4 \t train_loss=290.019 \t test_loss=318.115\n",
      "epoch=  5 \t train_loss=289.977 \t test_loss=318.251\n",
      "epoch=  6 \t train_loss=289.935 \t test_loss=318.403\n",
      "epoch=  7 \t train_loss=289.891 \t test_loss=318.573\n",
      "epoch=  8 \t train_loss=289.846 \t test_loss=318.763\n",
      "epoch=  9 \t train_loss=289.802 \t test_loss=318.977\n",
      "epoch= 10 \t train_loss=289.76 \t test_loss=319.217\n",
      "epoch= 11 \t train_loss=289.72 \t test_loss=319.488\n",
      "epoch= 12 \t train_loss=289.685 \t test_loss=319.793\n",
      "epoch= 13 \t train_loss=289.656 \t test_loss=320.138\n",
      "epoch= 14 \t train_loss=289.637 \t test_loss=320.528\n",
      "epoch= 15 \t train_loss=289.632 \t test_loss=320.97\n",
      "epoch= 16 \t train_loss=289.643 \t test_loss=321.473\n",
      "epoch= 17 \t train_loss=289.679 \t test_loss=322.045\n",
      "epoch= 18 \t train_loss=289.744 \t test_loss=322.699\n",
      "epoch= 19 \t train_loss=289.848 \t test_loss=323.446\n",
      "epoch= 20 \t train_loss=290.002 \t test_loss=324.302\n",
      "epoch= 21 \t train_loss=290.218 \t test_loss=325.285\n",
      "epoch= 22 \t train_loss=290.513 \t test_loss=326.418\n",
      "epoch= 23 \t train_loss=290.907 \t test_loss=327.725\n",
      "epoch= 24 \t train_loss=291.424 \t test_loss=329.236\n",
      "epoch= 25 \t train_loss=292.094 \t test_loss=330.988\n",
      "epoch= 26 \t train_loss=292.953 \t test_loss=333.023\n",
      "epoch= 27 \t train_loss=294.047 \t test_loss=335.393\n",
      "epoch= 28 \t train_loss=295.43 \t test_loss=338.158\n",
      "epoch= 29 \t train_loss=297.168 \t test_loss=341.392\n",
      "epoch= 30 \t train_loss=299.343 \t test_loss=345.181\n",
      "epoch= 31 \t train_loss=302.054 \t test_loss=349.629\n",
      "epoch= 32 \t train_loss=305.42 \t test_loss=354.862\n",
      "epoch= 33 \t train_loss=309.588 \t test_loss=361.028\n",
      "epoch= 34 \t train_loss=314.737 \t test_loss=368.309\n",
      "epoch= 35 \t train_loss=321.082 \t test_loss=376.92\n",
      "epoch= 36 \t train_loss=328.886 \t test_loss=387.119\n",
      "epoch= 37 \t train_loss=338.469 \t test_loss=399.22\n",
      "epoch= 38 \t train_loss=350.218 \t test_loss=413.596\n",
      "epoch= 39 \t train_loss=364.603 \t test_loss=430.699\n",
      "epoch= 40 \t train_loss=382.194 \t test_loss=451.074\n",
      "epoch= 41 \t train_loss=403.684 \t test_loss=475.374\n",
      "epoch= 42 \t train_loss=429.911 \t test_loss=504.388\n",
      "epoch= 43 \t train_loss=461.894 \t test_loss=539.069\n",
      "epoch= 44 \t train_loss=500.864 \t test_loss=580.563\n",
      "epoch= 45 \t train_loss=548.318 \t test_loss=630.253\n",
      "epoch= 46 \t train_loss=606.066 \t test_loss=689.81\n",
      "epoch= 47 \t train_loss=676.302 \t test_loss=761.249\n",
      "epoch= 48 \t train_loss=599.429 \t test_loss=683.008\n",
      "epoch= 49 \t train_loss=668.232 \t test_loss=753.087\n",
      "epoch= 50 \t train_loss=751.878 \t test_loss=837.202\n"
     ]
    }
   ],
   "source": [
    "weights_and_bias = (transpose(0.1 .* randn(13)), [0.0])\n",
    "\n",
    "η = 0.1  # Learning rate\n",
    "# n = 25   # Mini-batch size\n",
    "N = size(housing_data_train)[2]\n",
    "epoch = 0\n",
    "max_epoch = 50\n",
    "\n",
    "while loss(housing_data_test, median_house_price_test, weights_and_bias) ≥ 8.5\n",
    "    weights = weights_and_bias[1]\n",
    "    bias = weights_and_bias[2]\n",
    "    \n",
    "    idx_rand = rand(rng, 1:N)\n",
    "    x = Param(housing_data_train[:,idx_rand])\n",
    "    y = @diff abs(predict(x, weights_and_bias)[1] - median_house_price_train[idx_rand])\n",
    "    weights = weights - η*transpose(grad(y,x))\n",
    "    weights_and_bias = (weights, bias)\n",
    "    \n",
    "    train_loss = loss(housing_data_train, median_house_price_train, weights_and_bias);\n",
    "    test_loss = loss(housing_data_test, median_house_price_test, weights_and_bias);\n",
    "    @printf(\"epoch=%3d \\t train_loss=%6g \\t test_loss=%6g\\n\", epoch, train_loss, test_loss)\n",
    "    \n",
    "    epoch ≥ max_epoch && break\n",
    "    epoch = epoch+1\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously I dont have the objective function or something..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.0",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
